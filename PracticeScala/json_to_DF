val textFile = sc.textFile("/input/2M.ID.CONTENTS")
def FirstL(value: String) : Option[String] = {
	if(value.isEmpty) None 
	else Some(value.substring(0,1))
 }
def toAlpha (value: String): Option[String] = {
	if(value.matches("^[0-9a-z]*$")) Some(value) 
	else None
}
val split = textFile.flatMap(line => line.split("`~!@#$%^&*\\(\\)=+\\[\\]\\{\\}\\|;:,.<>?/\"\'_-")).flatMap(line => line.toLowerCase.split(" ")).flatMap(line => FirstL(line)).flatMap(line => toAlpha(line))
val splitLine = split.map(word => (word,1)).reduceByKey(_+_).sortByKey(true)
import org.apache.spark.sql.SQLContext
val sqlContext = new SQLContext(sc)
import sqlContext.implicits._
val df = splitLine.toDF("First_letter", "Number")
df.printSchema()
df.show()
